# Computer Science Basic

## 📖 목록

- [Bit Maniplulation](#bit-maniplulation)
- [Memory(Stack, Heap)](#memorystack-heap)
- [Recursive Function](#recursive-function)
- [Dynamic Programming](#dynamic-programming)
- [Big-O](#big-o)

## Bit Maniplulation

- 비트 연산자
  - NOT
    - 각 자릿수의 값은 반대로 바꾸는 연산
    - ~0111 = 1000
  - OR
    - 두 값의 각 자릿수를 비교하여, 둘 중 하나라도 1이 있다면 1, 아니면 0
    - 0101 | 0011 = 0111
  - XOR
    - 두 값의 각 자릿수를 비교하여, 값이 같으면 0, 다르면 1
    - 0101 ^ 0011 = 0110
  - AND
    - 두 값의 각 자릿수를 비교하여, 모두 1이면 1, 아니면 0
    - 0101 & 0011 = 0001
  - SHIFT
    - 비트 단위로 한 칸씩 미는 연산
    - 0001 << 2 = 0100
- 비트 연산 특징
  - 같은 값을 더하는 것은 왼쪽으로 한 번 시프트 하는 것과 같다.
  - 2<sup>n</sup>을 곱하는 것은 n만큼 왼쪽으로 시프트 하는 것과 같다.
  - 어떤 비트를 NOT 한 값과 그 비트를 XOR 하면 모든 비트가 1이다.
- 2의 보수와 음수
  - 컴퓨터는 정수를 저장할 때, 2의 보수 형태로 저장한다. 양수는 문제없지만, 음수를 표현할 때는 그 수의 절댓값에 부호비트를 1로 세팅한 후, 2의 보수를 취한 형태로 표현한다.
  - N 비트 음수에 대한 2의 보수는 2<sup>n</sup>에 대한 보수와 같다.
    - 4비트로 표현된 정수 -3을 예로 표현해 보면 아래와 같다.
    - 4비트 중 하나는 부호를 위한 비트로 숫자는 3비트로 표현된다.
    - -3: 절댓값 3의 2<sup>n</sup>=8의 보수와 -3에 대한 2의 보수는 같다.
    - 3은 8의 보수가 5이다. (0101)
    - -3은 1101이다.
- 산술 우측 시프트
  - `>>`, 2로 나눈 것과 같으며 `부호를 바꾸지 않는다.`
- 논리 우측 시프트
  - `>>>`, `부호가 바뀐다`, 논리 시프트를 계속하면 0이 된다.

## Memory(Stack, Heap)

| \     | 장점                                                                                                                      | 단점                                                                                                                                                    |
| ----- | ------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Stack | <ul><li>매우 빠른 액세스</li><li>변수를 명시적으로 해제할 필요 없음</li><li>CPU에 의해 공간이 효율적으로 관리됨</li></ul> | <ul><li>지역 변수만 관리</li><li>크기에 제한이 있음</li><li>변수의 크기를 조정할 수 없음</li><li>메모리 단편화가 되지 않음</li></ul>                    |
| Heap  | <ul><li>변수를 전역적으로 접근할 수 있음</li><li>메모리 크기 제한 없음</li></ul>                                          | <ul><li>(상대적으로) 느린 액세스</li><li>메모리를 관리해야 함</li><li>효율적인 공간 사용을 보장하지 못하면 메모리가 단편화되어 해제될 수 있음</li></ul> |

- 메모리 단편화

  - RAM에서 메모리의 공간이 작은 조각으로 나뉘어져 사용할 수 있는 메모리가 충분히 존재하지만, 할당(사용)할 수 없는 상태를 보고 `메모리 단편화`가 발생했다고 한다.
  - 내부 단편화(Internal Fragmentation)
    - 메모리를 할당할 때 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 프로세스에서 사용하는 메모리 공간이 낭비되는 상황
  - 외부 단편화(External Fragmentation)
    - 메모리가 할당되고 해제되는 작업이 반복될 때 작은 메모리가 중간중간 존재하게 된다. 이때 중간중간에 생긴 사용하지 않는 메모리가 많이 존재해서 총 메모리 공간은 충분하지만 실제로 할당할 수 없는 상황
  - 단편화를 해결하는 방법
    - Paging
    - Segmentation
    - Memory Pool

- 프로그램이 실행되기 위해서는 프로그램이 메모리에 로드(load)되어야 한다.
- 또한, 프로그램에 사용되는 변수들을 저장할 메모리도 필요하다.
- 메모리는 크게 4가지 공간이 있다.

  - Code, Data, Stack, Heap
  - Code 영역
    - 실행할 프로그램 코드가 저장되는 영역으로 CPU는 코드 영역에 저장된 명령어를 하나씩 가져가서 처리한다.
  - Data 영역
    - 프로그램의 `전역 변수`와 `정적(static) 변수`를 저장하는 영역으로 프로그램 시작과 함께 할당되며, 종료되면 소멸한다.
  - Stack 영역
    - 함수의 호출과 관계되는 `지역 변수`와 `매개 변수`를 저장하는 영역으로 함수의 호출과 함께 할당되며, 호출이 완료되면 소멸한다.
    - LIFO(Last-In First-Out) 방식으로 동작하며, 메모리의 높은 주소에서 낮은 주소 방향으로 할당된다.
  - Heap 영역
    - 사용자가 직접 관리할 수 있는, 관리해야만 하는 영역으로, 사용자에 의해 동작으로 할당되고 해제된다.
    - 메모리의 낮은 주소에서 높은 주소 방향으로 할당된다.

## Recursive Function

- 어떤 함수가 있을 때 그 안에서 자기 자신을 호출하는 함수이다.
- 짧고, 쉽다는 장점이 있으나 시간이 오래 걸리고, 공간을 많이 차지한다는 단점이 있다.
  - 함수를 호출하면 함수를 위한 공간과 메모리가 필요하게 되는데, 이 함수에 필요한 여러 가지 데이터를 채워줘야 하므로 시간도 오래 걸리고 공간도 많이 차지하는 것이다.
  - return에 의해 함수가 잡아두었던 메모리 공간을 다 쓰면 해제시켜야 하므로 성능이 상대적으로 낮아지게 된다.

## Dynamic Programming

- 큰 문제를 작은 문제로 나누어 문제를 해결하는 방식으로 각 문제는 모두 `한 번만` 풀어야 하므로 구한 답을 어딘가에 저장해두고, 다시 그 보다 큰 문제를 풀 때 똑같은 작은 문제가 나타나면 미리 저장해둔 값을 바로 활용한다.

- Divide and Conquer

  - 분할 정복 방식과 비슷하지만, 결정적인 차이점이 있는데, `작은 문제가 중복으로 일어나는지 일어나지 않는지`의 차이점이 있다.
    - 분할 정복은 큰 문제를 해결하기 어려워 단지 작은 문제로 나누어 푸는 방식이다.
    - 동적 계획법은 작은 문제들이 반복되는 것(답이 바뀌지 않음)을 이용해 푸는 방식이다.

- 따라서, 동적 계획법이 가능한 경우는 `작은 문제가 반복적으로 일어나는 경우`, `같은 문제는 구할 때마다 정답이 같은 경우`를 모두 만족해야 한다.

- Memoization

  - 작은 문제에 대한 답을 저장하고 이를 다시 활용하는 방식을 Memoization이라 한다.

- 구현 방법

  - Bottom-Up
    - 작은 문제부터 해결하는 방식이다.
  - Top-Down
    - 재귀를 활용한 방식이다. (큰 문제를 풀 때, 작은 문제가 풀리지 않았다면 그때 해결하는 방식)

## Big-O

- 코드의 복잡도를 대수학의 개념을 이용해 표현하는 방법이다.
- 빅오 표기법으로 계산할 때는 최고차항만 신경 쓴다.
  - 무엇을 실행하기 위해 드는 노력이 입력값이 커짐에 따라 기하급수적으로 증가하게 된다면 끝에는 아주 큰 숫자가 될 수 있다.
  - 최고차항은 보통 제일 빠르게 증가하는 함수이며, 이러한 함수들에는 꽤 많은 규칙이 있다.
    - ![image](/images/basic/big-o.png)
      - O(1)이 가장 작은 복잡도를 가진다.
      - O(logN)은 O(1)보다는 더 복잡하지만, 다항식보다는 덜 복잡하다.
      - 다항식의 복잡도는 지수가 증가함에 따라 증가한다.
      - 계수가 n의 양의 배수이면 지수 함수의 복잡도는 다항식의 복잡도보다 크다.
      - 팩토리얼은 지수함수보다 더 높은 복잡도를 가진다.
      - O(1) < O(logN) < O(N) < O(NlogN) < O(N<sup>2</sup>) < O(2<sup>N</sup>)
        - 왼쪽일수록 빠르다. (효율적이다.)
- 시간 복잡도와 공간 복잡도
  - 공간 복잡도는 시간 복잡도와 유사하다.
  - 시간 복잡도는 알고리즘의 실행 시간, 공간 복잡도는 알고리즘이 사용하는 메모리의 크기와 관련이 있다.
- 최선, 평균, 최악, 예상 복잡도

  - 일반적으로 알고리즘의 시간 복잡도는 최악의 경우를 고려한다.
  - 평균 복잡도는 알고리즘의 예상 성능을 설명하며, 때때로 각 시나리오의 확률을 계산하는 것이 포함된다.

- ![image](/images/basic/big-o2.png)
- 자주 쓰이는 Big-O 값
  - O(1)
    - stack push(pop)
  - O(logN)
    - binary tree
  - O(N)
    - for 문
  - O(NlogN)
    - quick sort
    - merge sort
    - heap sort
  - O(N<sup>2</sup>)
    - 이중 for 문
    - insertion sort
    - bubble sort
    - selection sort
  - O(2<sup>N</sup>)
    - 피보나치 수열
